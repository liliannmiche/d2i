# -*- coding: utf-8 -*-
"""
Created on Sat Apr  6 21:01:26 2013

@author: akusoka1
"""

from ibc_config import IBCConfig as cf
from multiprocessing.managers import BaseManager
from multiprocessing import Process
import Queue
import time
import cProfile



# existing class has connection, extending to add useful functions
class QueueManager(BaseManager):
    """Will combine multiprocessing manager and queue system.
    """
    pass


class MPMaster(Process):
    """Sets tasks, accepts results and writes them to HDF5.
    """

    def __init__(self, kill_workers, profiling=False):
        """Connects to a queue server.
        
        Params:
            n_wrk: number of workers to detect when all of them are finished
            profiling: whether to generate profiling information
        
        Class variables:
            self.task_max: total number of tasks, for reporting
            self.task_curr: current number of tasks, for reporting
        """
        super(MPMaster, self).__init__()
        # load host from file generated by manager
        host_ip = open(cf._host, "r").read()
        
        QueueManager.register('qtask')
        QueueManager.register('qresult')
        mng = QueueManager(address=(host_ip, cf._port), authkey=cf._key)
        mng.connect()
        self.qtask = mng.qtask()
        self.qresult = mng.qresult()
        
        # auxiliary variables
        self.more_tasks = True
        self.kill_workers = kill_workers
        self.start_time = time.time()
        self.task_max = 1
        self.task_curr = self.task_max  # countdown system 
        
        # profiling
        self.profiling = profiling
        if self.profiling:
            self.profiler = cProfile.Profile()
            self.profiler.enable()


    def terminate_workers(self):
        # put terminating messages in queue            
        full = False
        while (not full):
            try:
                self.qtask.put_nowait("empty")
            except Queue.Full:
                full = True

        
    def get_new_task(self):
        """Shoud *yield* tasks.
        """
        raise NotImplementedError


    def process_result(self, result, flush):
        """Processes the result - saves to database, etc.
        """
        raise NotImplementedError

        
    def report(self, last_t):
        """Prints time left.
        """
        # time of last obtained result
        t_passed = time.time() - last_t
        t_hours = t_passed / 3600
        t_minutes = (t_passed % 3600) / 60
        t_seconds = t_passed % 60
        
        # estimated remaining time, 99.99 to prevent division by zero
        temp_var = self.task_max - self.task_curr + 0.5
        t_rem = ((time.time() - self.start_time) / temp_var) * self.task_curr
        rem_hours = t_rem / 3600
        rem_minutes = (t_rem % 3600) / 60
        rem_seconds = t_rem % 60
        message = ('Tasks remaining: %d/%d ' % (self.task_curr, self.task_max) +
                   '(%d:%02d:%02d), ' % (rem_hours, rem_minutes, rem_seconds) +
                   'last result ' +
                   '%d:%02d:%02d ago' % (t_hours, t_minutes, t_seconds)) 
        # saving output to info file, because Triton stdout is slow as hell
        open(cf._dir + "log.txt", "w").write(message)
        print message

            
    def run(self):
        """Keeps input and output queues with limited length.
        """

        # task buffer for newly generated tasks, -1 means buffer is empty
        # because queue does not guarantee a task can be put in it
        task_buffer = -1  
        task_gen = self.get_new_task()  # task generator with "yield"
        self.start_time = time.time()
        last_t = time.time()  # time of acquiring the last result
        task_count = 0  # track the amount of tasks in queue for finalization
        
        working = True  # change to exit a cycle
        while working:
            t0 = time.time()            
            
            # add tasks to queue until its full
            full = False
            while (not full) and (self.more_tasks):
                try:
                    # try to get a new task
                    if task_buffer == -1:  # if the buffer is empty
                        try:
                            task_buffer = task_gen.next()
                            task_count += 1
                        except StopIteration:  # no more tasks left
                            task_buffer = -1  # leave the buffer empty
                            self.more_tasks = False
                            
                    # if there is a task to submit
                    if task_buffer != -1:
                        self.qtask.put_nowait(task_buffer)
                        task_buffer = -1  # task submitted, emptying buffer
                except Queue.Full:
                    full = True

            # read all results from queue
            empty = False
            while not empty:
                try:
                    result = self.qresult.get_nowait()
                    last_t = time.time()
                    # finalize task here, so that empty() would work
                    self.qresult.task_done()  
                    task_count -= 1

                    # saving results to disk
                    if isinstance(result, str):  # error string returned
                        print result
                    else:
                        flush = self.qresult.empty()  # flushing once a while
                        self.process_result(result, flush)
                except Queue.Empty:
                    empty = True

            # check if everything is done            
            if (not self.more_tasks) and (self.qtask.empty()):
                if task_count > 0:
                    print "Waiting for workers to finish..."
                    time.sleep(3)
                    continue
                working = False
                # sending termination signal to all workers if needed
                if self.kill_workers:
                    self.terminate_workers()
                     
            if cf._show_progress:
                self.report(last_t)
            time.sleep(max(3 - time.time() + t0, 0.1))  # sleep 0.1-3 seconds
                                        
        # profiling
        if self.profiling:
            self.profiler.disable()
            self.profiler.dump_stats(cf._dir + "MPMaster.prof")
            
        #print "Exiting master!"







